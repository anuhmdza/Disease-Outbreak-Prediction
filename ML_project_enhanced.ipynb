{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f08c977",
   "metadata": {},
   "source": [
    "This retrieves and cleans the census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4218511e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Census data saved as census_data_2016_2022.csv\n"
     ]
    }
   ],
   "source": [
    "from census import Census\n",
    "from us import states\n",
    "import pandas as pd\n",
    "\n",
    "# Replace with your Census API key\n",
    "CENSUS_API_KEY = \"fe6843e76d70b7f6bcc3ad4885d926a06f69c5c4\"\n",
    "\n",
    "c = Census(CENSUS_API_KEY)\n",
    "\n",
    "# Collect ACS data for all years\n",
    "acs_all_years = []\n",
    "\n",
    "for year in range(2016, 2023):\n",
    "    data = c.acs5.get(\n",
    "        (\"NAME\", \"B19013_001E\", \"B25064_001E\", \"B27010_001E\"),\n",
    "        geo={\"for\": \"state:*\"},\n",
    "        year=year\n",
    "    )\n",
    "    for row in data:\n",
    "        row['year'] = year\n",
    "    acs_all_years.extend(data)\n",
    "\n",
    "# Convert to DataFrame\n",
    "acs_df = pd.DataFrame(acs_all_years)\n",
    "\n",
    "# Rename columns\n",
    "acs_df.rename(columns={\n",
    "    \"NAME\": \"state_full\",\n",
    "    \"B19013_001E\": \"median_household_income\",\n",
    "    \"B25064_001E\": \"median_gross_rent\",\n",
    "    \"B27010_001E\": \"health_insurance_coverage\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Add state abbreviations\n",
    "fips_to_abbr = {str(s.fips).zfill(2): s.abbr for s in states.STATES}\n",
    "acs_df['state'] = acs_df['state'].map(fips_to_abbr)\n",
    "\n",
    "acs_df = acs_df[['state', 'year', 'median_household_income', 'median_gross_rent', 'health_insurance_coverage']]\n",
    "# Save to CSV\n",
    "acs_df.to_csv(\"census_data_2016_2022.csv\", index=False)\n",
    "print(\" Census data saved as census_data_2016_2022.csv\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842c3f1a",
   "metadata": {},
   "source": [
    "This retrieves and cleans the noaa data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b3095707",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emily\\AppData\\Local\\Temp\\ipykernel_3104\\3174612826.py:10: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  inventory = pd.read_csv(\"ghcnd-inventory.txt\", delim_whitespace=True, names=inv_cols)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " All done! Saved: climate_monthly_2016_2022.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# ----------------------------------------\n",
    "# STEP 1: Load and Filter Inventory\n",
    "# ----------------------------------------\n",
    "\n",
    "inv_cols = [\"station_id\", \"latitude\", \"longitude\", \"element\", \"first_year\", \"last_year\"]\n",
    "inventory = pd.read_csv(\"ghcnd-inventory.txt\", delim_whitespace=True, names=inv_cols)\n",
    "inv_filtered = inventory[inventory[\"element\"].isin([\"TMAX\", \"TMIN\", \"PRCP\"])]\n",
    "\n",
    "# Only stations with all 3 core elements\n",
    "counts = inv_filtered.groupby(\"station_id\")[\"element\"].nunique().reset_index()\n",
    "counts = counts[counts[\"element\"] == 3]\n",
    "station_elements = inv_filtered.merge(counts[[\"station_id\"]], on=\"station_id\", how=\"inner\")\n",
    "recent_stations = station_elements[station_elements[\"last_year\"] >= 2022]\n",
    "\n",
    "# ----------------------------------------\n",
    "# STEP 2: Station Metadata and Best Stations\n",
    "# ----------------------------------------\n",
    "\n",
    "colspecs = [(0, 11), (12, 20), (21, 30), (31, 37), (38, 40), (41, 71)]\n",
    "colnames = [\"station_id\", \"lat\", \"lon\", \"elev\", \"state\", \"name\"]\n",
    "stations = pd.read_fwf(\"ghcnd-stations.txt\", colspecs=colspecs, names=colnames)\n",
    "\n",
    "merged = recent_stations.merge(stations, on=\"station_id\")\n",
    "us_states = [\n",
    "    'AL','AK','AZ','AR','CA','CO','CT','DE','FL','GA','HI','ID','IL','IN','IA','KS','KY','LA','ME','MD',\n",
    "    'MA','MI','MN','MS','MO','MT','NE','NV','NH','NJ','NM','NY','NC','ND','OH','OK','OR','PA','RI','SC',\n",
    "    'SD','TN','TX','UT','VT','VA','WA','WV','WI','WY','DC'\n",
    "]\n",
    "merged = merged[merged[\"state\"].isin(us_states)]\n",
    "best_stations = merged.sort_values(by=[\"state\", \"elev\"]).groupby(\"state\").first().reset_index()\n",
    "best_stations.to_csv(\"best_stations_per_state.csv\", index=False)\n",
    "\n",
    "# ----------------------------------------\n",
    "# STEP 3: Download .dly Files\n",
    "# ----------------------------------------\n",
    "\n",
    "os.makedirs(\"dly_files\", exist_ok=True)\n",
    "base_url = \"https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/all\"\n",
    "\n",
    "for station_id in best_stations[\"station_id\"]:\n",
    "    file_path = f\"dly_files/{station_id}.dly\"\n",
    "    if not os.path.exists(file_path):\n",
    "        url = f\"{base_url}/{station_id}.dly\"\n",
    "        r = requests.get(url)\n",
    "        if r.status_code == 200:\n",
    "            with open(file_path, \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "            print(f\" Downloaded {station_id}.dly\")\n",
    "        else:\n",
    "            print(f\"Failed to download {station_id}\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# STEP 4: Parse .dly Files for 2016â€“2022\n",
    "# ----------------------------------------\n",
    "\n",
    "def parse_dly_file(file_path, station_id, state, years=range(2016, 2023)):\n",
    "    records = []\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            year = int(line[11:15])\n",
    "            month = int(line[15:17])\n",
    "            element = line[17:21]\n",
    "\n",
    "            if year not in years or element not in [\"TMAX\", \"TMIN\", \"PRCP\"]:\n",
    "                continue\n",
    "\n",
    "            for day in range(1, 32):\n",
    "                value_str = line[21 + (day - 1) * 8 : 26 + (day - 1) * 8]\n",
    "                try:\n",
    "                    value = int(value_str[:5])\n",
    "                    if value == -9999:\n",
    "                        continue\n",
    "                    date = pd.to_datetime(f\"{year}-{month:02d}-{day:02d}\", errors=\"coerce\")\n",
    "                    if pd.notna(date):\n",
    "                        records.append({\n",
    "                            \"date\": date,\n",
    "                            \"state\": state,\n",
    "                            \"element\": element,\n",
    "                            \"value\": value / 10\n",
    "                        })\n",
    "                except:\n",
    "                    continue\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# Parse all files\n",
    "all_dfs = []\n",
    "for _, row in best_stations.iterrows():\n",
    "    path = f\"dly_files/{row['station_id']}.dly\"\n",
    "    if os.path.exists(path):\n",
    "        df = parse_dly_file(path, row[\"station_id\"], row[\"state\"])\n",
    "        all_dfs.append(df)\n",
    "\n",
    "df_all = pd.concat(all_dfs)\n",
    "\n",
    "# ----------------------------------------\n",
    "# STEP 5: Pivot + Monthly Aggregation\n",
    "# ----------------------------------------\n",
    "\n",
    "df_all[\"year\"] = df_all[\"date\"].dt.year\n",
    "df_all[\"month\"] = df_all[\"date\"].dt.month\n",
    "\n",
    "monthly = df_all.groupby([\"state\", \"year\", \"month\", \"element\"])[\"value\"].mean().unstack().reset_index()\n",
    "monthly.columns.name = None\n",
    "monthly.rename(columns={\"PRCP\": \"Precip_mm\", \"TMAX\": \"Max_Temp_C\", \"TMIN\": \"Min_Temp_C\"}, inplace=True)\n",
    "\n",
    "monthly.to_csv(\"climate_monthly_2016_2022.csv\", index=False)\n",
    "print(\" All done! Saved: climate_monthly_2016_2022.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1a9b4a",
   "metadata": {},
   "source": [
    "This retrieves and cleans the nnds data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3f6ee1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Notes', 'Disease', 'Disease Code', 'Year', 'Year Code', 'Regions/States', 'Regions/States Code', 'Case Count']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Notes</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Disease Code</th>\n",
       "      <th>Year</th>\n",
       "      <th>Year Code</th>\n",
       "      <th>Regions/States</th>\n",
       "      <th>Regions/States Code</th>\n",
       "      <th>Case Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Diphtheria</td>\n",
       "      <td>10040.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>U.S.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Diphtheria</td>\n",
       "      <td>10040.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>New England</td>\n",
       "      <td>REGION1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Diphtheria</td>\n",
       "      <td>10040.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Diphtheria</td>\n",
       "      <td>10040.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Maine</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Diphtheria</td>\n",
       "      <td>10040.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>categorized as Suppressed. More information: h...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>7. Values in charts and maps refer to statisti...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>designation assigned to category labels, such ...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>8. Any variation of disease incidence by race ...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>cultural, behavioral, and social factors inclu...</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Notes     Disease  \\\n",
       "0                                                  NaN  Diphtheria   \n",
       "1                                                  NaN  Diphtheria   \n",
       "2                                                  NaN  Diphtheria   \n",
       "3                                                  NaN  Diphtheria   \n",
       "4                                                  NaN  Diphtheria   \n",
       "..                                                 ...         ...   \n",
       "593  categorized as Suppressed. More information: h...        None   \n",
       "594  7. Values in charts and maps refer to statisti...        None   \n",
       "595  designation assigned to category labels, such ...        None   \n",
       "596  8. Any variation of disease incidence by race ...        None   \n",
       "597  cultural, behavioral, and social factors inclu...        None   \n",
       "\n",
       "     Disease Code    Year  Year Code Regions/States Regions/States Code  \\\n",
       "0         10040.0  2022.0     2022.0  United States                U.S.   \n",
       "1         10040.0  2022.0     2022.0    New England             REGION1   \n",
       "2         10040.0  2022.0     2022.0    Connecticut                  09   \n",
       "3         10040.0  2022.0     2022.0          Maine                  23   \n",
       "4         10040.0  2022.0     2022.0  Massachusetts                  25   \n",
       "..            ...     ...        ...            ...                 ...   \n",
       "593           NaN     NaN        NaN           None                None   \n",
       "594           NaN     NaN        NaN           None                None   \n",
       "595           NaN     NaN        NaN           None                None   \n",
       "596           NaN     NaN        NaN           None                None   \n",
       "597           NaN     NaN        NaN           None                None   \n",
       "\n",
       "    Case Count  \n",
       "0            1  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "..         ...  \n",
       "593       None  \n",
       "594       None  \n",
       "595       None  \n",
       "596       None  \n",
       "597       None  \n",
       "\n",
       "[598 rows x 8 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Try reading it as a tab-separated file instead of Excel\n",
    "nndss_raw = pd.read_csv(\"NNDSS Annual Summary Data 2016-2022 (2).xls\", sep=\"\\t\", engine=\"python\", encoding=\"utf-8\")\n",
    "\n",
    "# Display column names\n",
    "print(nndss_raw.columns.tolist())\n",
    "\n",
    "# Quick look\n",
    "nndss_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "610fa0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cleaned and saved as 'nndss_dtp_mmr_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the file (tab-delimited)\n",
    "nndss_df = pd.read_csv(\"NNDSS Annual Summary Data 2016-2022 (2).xls\", sep=\"\\t\", engine=\"python\")\n",
    "\n",
    "# Keep only the columns we need\n",
    "nndss_df = nndss_df[[\"Year\", \"Regions/States\", \"Disease\", \"Case Count\"]]\n",
    "\n",
    "# Rename for clarity\n",
    "nndss_df.columns = [\"year\", \"state\", \"disease\", \"cases\"]\n",
    "\n",
    "# Filter to diseases of interest\n",
    "diseases_of_interest = [\"Diphtheria\", \"Tetanus\", \"Pertussis\", \"Measles\", \"Mumps\", \"Rubella\"]\n",
    "nndss_df = nndss_df[nndss_df[\"disease\"].isin(diseases_of_interest)]\n",
    "\n",
    "# Remove rows where state is US Territories or Totals\n",
    "us_states = [\n",
    "    'Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware',\n",
    "    'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky',\n",
    "    'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi',\n",
    "    'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico',\n",
    "    'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania',\n",
    "    'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont',\n",
    "    'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming'\n",
    "]\n",
    "nndss_df = nndss_df[nndss_df[\"state\"].isin(us_states)]\n",
    "\n",
    "# Map state names to abbreviations\n",
    "import us\n",
    "state_abbrev = {state.name: state.abbr for state in us.states.STATES}\n",
    "nndss_df[\"state\"] = nndss_df[\"state\"].map(state_abbrev)\n",
    "\n",
    "# Convert case count to numeric\n",
    "nndss_df[\"cases\"] = pd.to_numeric(nndss_df[\"cases\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "# Final clean dataframe\n",
    "nndss_cleaned = nndss_df[[\"state\", \"year\", \"disease\", \"cases\"]]\n",
    "\n",
    "# Save it\n",
    "nndss_cleaned.to_csv(\"nndss_dtp_mmr_cleaned.csv\", index=False)\n",
    "print(\" Cleaned and saved as 'nndss_dtp_mmr_cleaned.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec700e3",
   "metadata": {},
   "source": [
    "This rertrieves and cleans the vaccination data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "67ae1b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Vaccination data cleaned and saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "vacc = pd.read_csv(\"Vaccination_Coverage_and_Exemptions_among_Kindergartners_20250326.csv\")\n",
    "\n",
    "# Filter to only 'States' geography\n",
    "vacc = vacc[vacc[\"Geography Type\"] == \"States\"]\n",
    "\n",
    "# Extract year from 'School Year' like \"2021-22\"\n",
    "vacc[\"year\"] = vacc[\"School Year\"].str.extract(r\"(\\d{4})\").astype(float)\n",
    "\n",
    "# Filter to 2016â€“2022\n",
    "vacc = vacc[vacc[\"year\"].between(2016, 2022)]\n",
    "\n",
    "# Clean and keep relevant columns\n",
    "vacc = vacc[[\"Geography\", \"year\", \"Vaccine/Exemption\", \"Estimate (%)\"]]\n",
    "vacc.rename(columns={\"Geography\": \"state\"}, inplace=True)\n",
    "\n",
    "# Convert Estimate to numeric (force errors to NaN)\n",
    "vacc[\"Estimate (%)\"] = pd.to_numeric(vacc[\"Estimate (%)\"], errors=\"coerce\")\n",
    "\n",
    "# Pivot the table: One column per vaccine or exemption type\n",
    "vacc_pivot = vacc.pivot_table(\n",
    "    index=[\"state\", \"year\"],\n",
    "    columns=\"Vaccine/Exemption\",\n",
    "    values=\"Estimate (%)\",\n",
    "    aggfunc=\"mean\"  # Handle duplicates\n",
    ").reset_index()\n",
    "\n",
    "# Save result\n",
    "vacc_pivot.to_csv(\"cleaned_vaccination_data_2016_2022.csv\", index=False)\n",
    "print(\" Vaccination data cleaned and saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddb3847",
   "metadata": {},
   "source": [
    "This merges all the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f732c1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Final dataset saved as 'final_model_dataset_2016_2022.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 1: Load datasets\n",
    "# -------------------------------\n",
    "\n",
    "vacc = pd.read_csv(\"cleaned_vaccination_data_2016_2022.csv\")\n",
    "nndss = pd.read_csv(\"nndss_dtp_mmr_cleaned.csv\")\n",
    "climate = pd.read_csv(\"climate_monthly_2016_2022.csv\")\n",
    "census = pd.read_csv(\"census_data_2016_2022.csv\")\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 2: Preprocess vaccination data\n",
    "# -------------------------------\n",
    "\n",
    "# Ensure correct types\n",
    "vacc['year'] = vacc['year'].astype(int)\n",
    "\n",
    "# Map state names to abbreviations\n",
    "state_mapping = {\n",
    "    'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR', 'California': 'CA',\n",
    "    'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE', 'Florida': 'FL', 'Georgia': 'GA',\n",
    "    'Hawaii': 'HI', 'Idaho': 'ID', 'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA',\n",
    "    'Kansas': 'KS', 'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS', 'Missouri': 'MO',\n",
    "    'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV', 'New Hampshire': 'NH', 'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM', 'New York': 'NY', 'North Carolina': 'NC', 'North Dakota': 'ND', 'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK', 'Oregon': 'OR', 'Pennsylvania': 'PA', 'Rhode Island': 'RI', 'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD', 'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT', 'Vermont': 'VT',\n",
    "    'Virginia': 'VA', 'Washington': 'WA', 'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY'\n",
    "}\n",
    "vacc['state'] = vacc['state'].map(state_mapping)\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 3: Preprocess NNDSS outbreak data\n",
    "# -------------------------------\n",
    "\n",
    "nndss['year'] = nndss['year'].astype(int)\n",
    "nndss['state'] = nndss['state'].str.upper()\n",
    "\n",
    "# Aggregate by state and year\n",
    "nndss_grouped = (\n",
    "    nndss.groupby(['state', 'year'])['cases']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 4: Preprocess climate data\n",
    "# -------------------------------\n",
    "\n",
    "climate['year'] = climate['year'].astype(int)\n",
    "climate['state'] = climate['state'].str.upper()\n",
    "\n",
    "# Aggregate monthly to yearly per state\n",
    "climate_grouped = (\n",
    "    climate.groupby(['state', 'year']).agg({\n",
    "        'Precip_mm': 'mean',\n",
    "        'Max_Temp_C': 'mean',\n",
    "        'Min_Temp_C': 'mean'\n",
    "    }).reset_index()\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 5: Preprocess census data\n",
    "# -------------------------------\n",
    "\n",
    "census['year'] = census['year'].astype(int)\n",
    "census['state'] = census['state'].str.upper()\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 6: Merge all data\n",
    "# -------------------------------\n",
    "\n",
    "merged = climate_grouped.merge(census, on=['state', 'year'], how='left')\n",
    "merged = merged.merge(vacc, on=['state', 'year'], how='left')\n",
    "merged = merged.merge(nndss_grouped, on=['state', 'year'], how='left')\n",
    "\n",
    "# Fill missing cases with 0\n",
    "merged['cases'] = merged['cases'].fillna(0).astype(int)\n",
    "\n",
    "# -------------------------------\n",
    "# STEP 7: Export final dataset\n",
    "# -------------------------------\n",
    "\n",
    "merged.to_csv(\"final_model_dataset_2016_2022.csv\", index=False)\n",
    "print(\" Final dataset saved as 'final_model_dataset_2016_2022.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fbb34d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state                         0\n",
       "year                          0\n",
       "Precip_mm                     0\n",
       "Max_Temp_C                    6\n",
       "Min_Temp_C                    6\n",
       "median_household_income       0\n",
       "median_gross_rent             0\n",
       "health_insurance_coverage     0\n",
       "DTP, DTaP, or DT              7\n",
       "Exemption                     4\n",
       "Hepatitis B                  25\n",
       "MMR                           6\n",
       "MMR (PAC)                    49\n",
       "Polio                         6\n",
       "Varicella                     6\n",
       "cases                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged\n",
    "merged.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dd24a9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state                         0.000000\n",
       "year                          0.000000\n",
       "Precip_mm                     0.000000\n",
       "Max_Temp_C                    1.929260\n",
       "Min_Temp_C                    1.929260\n",
       "median_household_income       0.000000\n",
       "median_gross_rent             0.000000\n",
       "health_insurance_coverage     0.000000\n",
       "DTP, DTaP, or DT              2.250804\n",
       "Exemption                     1.286174\n",
       "Hepatitis B                   8.038585\n",
       "MMR                           1.929260\n",
       "MMR (PAC)                    15.755627\n",
       "Polio                         1.929260\n",
       "Varicella                     1.929260\n",
       "cases                         0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent= merged.isnull().sum() * 100/len(merged)\n",
    "percent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1235951",
   "metadata": {},
   "source": [
    "This creates a variation of the merged dataset for models that dont handle missing values well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ca2be680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Missing values filled per state and saved as 'final_model_dataset_2016_2022_imputed_by_state.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your final dataset\n",
    "df = pd.read_csv(\"final_model_dataset_2016_2022.csv\")\n",
    "\n",
    "# Columns to impute\n",
    "vaccine_cols = [\n",
    "    'DTP, DTaP, or DT', 'MMR', 'MMR (PAC)', 'Polio', 'Varicella',\n",
    "    'Hepatitis B', 'Exemption'\n",
    "]\n",
    "numeric_cols = [\n",
    "    'Precip_mm', 'Max_Temp_C', 'Min_Temp_C',\n",
    "    'median_household_income', 'median_gross_rent', 'health_insurance_coverage'\n",
    "]\n",
    "\n",
    "cols_to_fill = vaccine_cols + numeric_cols\n",
    "\n",
    "# 1. Create missing indicators for vaccine columns\n",
    "for col in vaccine_cols:\n",
    "    df[f\"{col}_missing\"] = df[col].isna().astype(int)\n",
    "\n",
    "# 2. Fill missing values with median per state\n",
    "df[cols_to_fill] = df.groupby('state')[cols_to_fill].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# 3. Optional: Save the imputed dataset\n",
    "df.to_csv(\"final_model_dataset_2016_2022_imputed_by_state.csv\", index=False)\n",
    "print(\" Missing values filled per state and saved as 'final_model_dataset_2016_2022_imputed_by_state.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a85cf368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>year</th>\n",
       "      <th>Precip_mm</th>\n",
       "      <th>Max_Temp_C</th>\n",
       "      <th>Min_Temp_C</th>\n",
       "      <th>median_household_income</th>\n",
       "      <th>median_gross_rent</th>\n",
       "      <th>health_insurance_coverage</th>\n",
       "      <th>DTP, DTaP, or DT</th>\n",
       "      <th>Exemption</th>\n",
       "      <th>...</th>\n",
       "      <th>Polio</th>\n",
       "      <th>Varicella</th>\n",
       "      <th>cases</th>\n",
       "      <th>DTP, DTaP, or DT_missing</th>\n",
       "      <th>MMR_missing</th>\n",
       "      <th>MMR (PAC)_missing</th>\n",
       "      <th>Polio_missing</th>\n",
       "      <th>Varicella_missing</th>\n",
       "      <th>Hepatitis B_missing</th>\n",
       "      <th>Exemption_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>2020</td>\n",
       "      <td>3.413333</td>\n",
       "      <td>11.856667</td>\n",
       "      <td>5.636667</td>\n",
       "      <td>77790.0</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>711104.0</td>\n",
       "      <td>80.90</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>80.75</td>\n",
       "      <td>78.95</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.259029</td>\n",
       "      <td>9.401636</td>\n",
       "      <td>4.335281</td>\n",
       "      <td>80287.0</td>\n",
       "      <td>1279.0</td>\n",
       "      <td>709438.0</td>\n",
       "      <td>78.00</td>\n",
       "      <td>3.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>77.10</td>\n",
       "      <td>76.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AK</td>\n",
       "      <td>2022</td>\n",
       "      <td>6.153206</td>\n",
       "      <td>10.478086</td>\n",
       "      <td>5.192660</td>\n",
       "      <td>86370.0</td>\n",
       "      <td>1345.0</td>\n",
       "      <td>706392.0</td>\n",
       "      <td>83.80</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>84.40</td>\n",
       "      <td>81.80</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AL</td>\n",
       "      <td>2016</td>\n",
       "      <td>3.854682</td>\n",
       "      <td>25.265154</td>\n",
       "      <td>18.404720</td>\n",
       "      <td>44758.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>4761291.0</td>\n",
       "      <td>93.80</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>...</td>\n",
       "      <td>93.80</td>\n",
       "      <td>93.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AL</td>\n",
       "      <td>2017</td>\n",
       "      <td>6.516683</td>\n",
       "      <td>24.726720</td>\n",
       "      <td>18.341777</td>\n",
       "      <td>46472.0</td>\n",
       "      <td>747.0</td>\n",
       "      <td>4770692.0</td>\n",
       "      <td>92.70</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>92.70</td>\n",
       "      <td>92.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>WV</td>\n",
       "      <td>2020</td>\n",
       "      <td>2.739748</td>\n",
       "      <td>19.282682</td>\n",
       "      <td>6.726777</td>\n",
       "      <td>48037.0</td>\n",
       "      <td>732.0</td>\n",
       "      <td>1778080.0</td>\n",
       "      <td>97.25</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>...</td>\n",
       "      <td>97.40</td>\n",
       "      <td>97.90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>WV</td>\n",
       "      <td>2021</td>\n",
       "      <td>2.662434</td>\n",
       "      <td>19.160215</td>\n",
       "      <td>6.716009</td>\n",
       "      <td>50884.0</td>\n",
       "      <td>770.0</td>\n",
       "      <td>1773559.0</td>\n",
       "      <td>96.50</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>...</td>\n",
       "      <td>96.60</td>\n",
       "      <td>98.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>WV</td>\n",
       "      <td>2022</td>\n",
       "      <td>2.480885</td>\n",
       "      <td>18.496595</td>\n",
       "      <td>5.598281</td>\n",
       "      <td>55217.0</td>\n",
       "      <td>831.0</td>\n",
       "      <td>1759522.0</td>\n",
       "      <td>95.60</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>95.60</td>\n",
       "      <td>95.60</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>WY</td>\n",
       "      <td>2021</td>\n",
       "      <td>0.708996</td>\n",
       "      <td>20.369684</td>\n",
       "      <td>4.805035</td>\n",
       "      <td>68002.0</td>\n",
       "      <td>878.0</td>\n",
       "      <td>567043.0</td>\n",
       "      <td>92.50</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>93.80</td>\n",
       "      <td>93.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>WY</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.930768</td>\n",
       "      <td>17.142874</td>\n",
       "      <td>2.785259</td>\n",
       "      <td>72495.0</td>\n",
       "      <td>933.0</td>\n",
       "      <td>567826.0</td>\n",
       "      <td>89.40</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>90.10</td>\n",
       "      <td>90.50</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    state  year  Precip_mm  Max_Temp_C  Min_Temp_C  median_household_income  \\\n",
       "0      AK  2020   3.413333   11.856667    5.636667                  77790.0   \n",
       "1      AK  2021   0.259029    9.401636    4.335281                  80287.0   \n",
       "2      AK  2022   6.153206   10.478086    5.192660                  86370.0   \n",
       "3      AL  2016   3.854682   25.265154   18.404720                  44758.0   \n",
       "4      AL  2017   6.516683   24.726720   18.341777                  46472.0   \n",
       "..    ...   ...        ...         ...         ...                      ...   \n",
       "306    WV  2020   2.739748   19.282682    6.726777                  48037.0   \n",
       "307    WV  2021   2.662434   19.160215    6.716009                  50884.0   \n",
       "308    WV  2022   2.480885   18.496595    5.598281                  55217.0   \n",
       "309    WY  2021   0.708996   20.369684    4.805035                  68002.0   \n",
       "310    WY  2022   0.930768   17.142874    2.785259                  72495.0   \n",
       "\n",
       "     median_gross_rent  health_insurance_coverage  DTP, DTaP, or DT  \\\n",
       "0               1240.0                   711104.0             80.90   \n",
       "1               1279.0                   709438.0             78.00   \n",
       "2               1345.0                   706392.0             83.80   \n",
       "3                728.0                  4761291.0             93.80   \n",
       "4                747.0                  4770692.0             92.70   \n",
       "..                 ...                        ...               ...   \n",
       "306              732.0                  1778080.0             97.25   \n",
       "307              770.0                  1773559.0             96.50   \n",
       "308              831.0                  1759522.0             95.60   \n",
       "309              878.0                   567043.0             92.50   \n",
       "310              933.0                   567826.0             89.40   \n",
       "\n",
       "     Exemption  ...  Polio  Varicella  cases  DTP, DTaP, or DT_missing  \\\n",
       "0     2.666667  ...  80.75      78.95      0                         1   \n",
       "1     3.066667  ...  77.10      76.10      0                         0   \n",
       "2     3.800000  ...  84.40      81.80      3                         0   \n",
       "3     0.466667  ...  93.80      93.80      0                         0   \n",
       "4     0.600000  ...  92.70      92.70      0                         0   \n",
       "..         ...  ...    ...        ...    ...                       ...   \n",
       "306   0.150000  ...  97.40      97.90      0                         1   \n",
       "307   0.100000  ...  96.60      98.00      0                         0   \n",
       "308   0.000000  ...  95.60      95.60     16                         0   \n",
       "309   2.600000  ...  93.80      93.60      0                         0   \n",
       "310   3.200000  ...  90.10      90.50      2                         0   \n",
       "\n",
       "     MMR_missing  MMR (PAC)_missing  Polio_missing  Varicella_missing  \\\n",
       "0              1                  1              1                  1   \n",
       "1              0                  0              0                  0   \n",
       "2              0                  0              0                  0   \n",
       "3              0                  1              0                  0   \n",
       "4              0                  0              0                  0   \n",
       "..           ...                ...            ...                ...   \n",
       "306            1                  1              1                  1   \n",
       "307            0                  0              0                  0   \n",
       "308            0                  0              0                  0   \n",
       "309            0                  0              0                  0   \n",
       "310            0                  0              0                  0   \n",
       "\n",
       "     Hepatitis B_missing  Exemption_missing  \n",
       "0                      1                  0  \n",
       "1                      0                  0  \n",
       "2                      0                  0  \n",
       "3                      1                  0  \n",
       "4                      1                  0  \n",
       "..                   ...                ...  \n",
       "306                    1                  1  \n",
       "307                    0                  0  \n",
       "308                    0                  0  \n",
       "309                    0                  0  \n",
       "310                    0                  0  \n",
       "\n",
       "[311 rows x 23 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef94b64b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a97aa72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
